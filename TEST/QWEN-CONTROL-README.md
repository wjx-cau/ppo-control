# Qwen 视觉控制系统 - 优化说明

## 📋 更新内容

### 1. ✅ 迭代数据自动分类存储
每次运行都会在 `QWEN-OUTPUT` 文件夹下创建一个时间戳命名的运行目录，每次迭代的所有数据都存放在独立的子文件夹中。

**目录结构示例：**
```
QWEN-OUTPUT/
└── run_20251019_143025/           # 运行时间戳
    ├── iteration_01/               # 第1次迭代
    │   ├── camera_view.png        # 摄像头图像
    │   ├── robot_state.json       # 机器人状态
    │   ├── analysis.json          # Qwen分析结果
    │   └── command.txt            # 控制命令
    ├── iteration_02/               # 第2次迭代
    │   ├── camera_view.png
    │   ├── robot_state.json
    │   ├── analysis.json
    │   └── command.txt
    ├── iteration_03/               # 第3次迭代
    │   └── ...
    └── summary.txt                 # 总结报告
```

### 2. ✅ 优化提示词（简化输出）
**旧格式**（冗长复杂）：
```json
{
  "what_i_see": "...",
  "analysis": "...",
  "movement_plan": {
    "direction": "...",
    "reason": "...",
    "expected_change": "..."
  },
  "next_action": {
    "key": "K",
    "duration": 0.15,
    "why": "..."
  }
}
```

**新格式**（简洁清晰）：
```json
{
  "summary": "看到绿色植物，有多片叶子",
  "control": {
    "key": "K",
    "duration": 0.3
  }
}
```

现在只需要：
- **summary**: 一句话总结看到的内容
- **control**: 控制指令（按键+时长）

让模型自由发挥，不提供示例，避免过度约束。

### 3. ✅ 连续控制与历史上下文
系统现在会在每次迭代时告诉 Qwen：
- **上次控制**: 上一次执行的按键和时长
- **上次总结**: 上一次看到的内容

**提示词核心**：
```
**重要说明：这是一个连续控制任务！**
你需要根据历史记录（上次控制动作和看到的内容）来分析当前的观察结果，
理解控制与观察之间的关系。

# 上一次的控制与观察：
- **上次控制**: K 键 0.3秒
- **上次看到**: 看到绿色植物，有多片叶子

请根据上次的控制动作，分析当前画面的变化，理解控制与观察的关系。
```

这样模型可以：
1. 理解自己的控制效果（例如：我向右转了，画面确实向左移动了）
2. 形成连续的探索策略（例如：上次看到了植物左侧，这次继续向左看看有什么）
3. 避免重复无效的动作

## 🚀 使用方法

### 1. 启动模拟器
```bash
cd /Users/wjx_macair/Desktop/code/TEST
python pybullt/test_environment.py
```

### 2. 等待演示结束（约5秒），然后运行控制脚本
```bash
python qwen-vision-control.py
```

### 3. 查看结果
所有数据会自动保存到 `QWEN-OUTPUT/run_YYYYMMDD_HHMMSS/` 目录下。

## 📊 输出文件说明

| 文件 | 说明 |
|------|------|
| `camera_view.png` | 该迭代的摄像头图像 |
| `robot_state.json` | 机器人当前状态（关节角度、位置等） |
| `analysis.json` | Qwen的完整分析结果（JSON格式） |
| `command.txt` | 执行的控制命令（人类可读格式） |
| `summary.txt` | 整个运行的总结报告 |

## 🎯 优化效果

1. **数据管理更清晰**: 每次运行独立存储，不会混乱
2. **模型输出更简洁**: 减少token消耗，提高响应速度
3. **连续控制更智能**: 模型能理解控制效果，形成探索策略

## 🔧 测试

运行测试脚本验证文件夹结构：
```bash
python test-new-structure.py
```

## 📝 示例运行流程

```
迭代 1:
  观察: 看到灰色地面
  控制: K 0.8s (大幅旋转搜索)
  
迭代 2:
  观察: 看到绿色物体在左侧边缘
  控制: I 0.2s (向左对准)
  
迭代 3:
  观察: 看到绿色植物，有叶子和茎干
  控制: J 0.3s (抬头看顶部)
```

每次迭代都会记住上一次的控制和观察，形成连贯的探索行为。
